{
  "hash": "76ad535056a290da99a4716189ceba8f",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: '**Data Preparation**'\n---\n\n\n***\nThis notebook demonstrates the `src.data_prep` pipeline:\n\n1. Loads the raw CSV  \n2. Shows a before/after sample of 10 tweets  \n3. Saves the cleaned data to Parquet and prints the output path  \n\n## Notebook Outline \n- [Before / After Cleaning](#before--after-cleaning)  \n- [Save to Parquet](#save-to-parquet)\n\n\n::: {#2d5a3c3a .cell execution_count=1}\n``` {.python .cell-code}\n# standard imports\nfrom twitter_airline_analysis.data_prep import load_raw, preprocess, save_parquet\nimport pandas as pd\n# ── Cell: regenerate_splits.py ──────────────────────────────────────────────\nfrom pathlib import Path\nfrom sklearn.model_selection import train_test_split\n\nPROJ_ROOT = Path.cwd().parent        # one level up from notebooks/\nRAW_DIR   = PROJ_ROOT / \"data\" / \"raw\"\nPROC_DIR  = PROJ_ROOT / \"data\" / \"processed\"\nPROC_DIR.mkdir(parents=True, exist_ok=True)\n\n# load the raw DataFrame\ndf_raw = load_raw()\nprint(f\"Raw data: {df_raw.shape[0]:,} rows × {df_raw.shape[1]} columns\")\ndf_raw.head(10)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nRaw data: 14,640 rows × 15 columns\n```\n:::\n\n::: {.cell-output .cell-output-display execution_count=1}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>tweet_id</th>\n      <th>airline_sentiment</th>\n      <th>airline_sentiment_confidence</th>\n      <th>negativereason</th>\n      <th>negativereason_confidence</th>\n      <th>airline</th>\n      <th>airline_sentiment_gold</th>\n      <th>name</th>\n      <th>negativereason_gold</th>\n      <th>retweet_count</th>\n      <th>text</th>\n      <th>tweet_coord</th>\n      <th>tweet_created</th>\n      <th>tweet_location</th>\n      <th>user_timezone</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>570306133677760513</td>\n      <td>neutral</td>\n      <td>1.0000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Virgin America</td>\n      <td>NaN</td>\n      <td>cairdin</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>@VirginAmerica What @dhepburn said.</td>\n      <td>NaN</td>\n      <td>2015-02-24 11:35:52 -0800</td>\n      <td>NaN</td>\n      <td>Eastern Time (US &amp; Canada)</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>570301130888122368</td>\n      <td>positive</td>\n      <td>0.3486</td>\n      <td>NaN</td>\n      <td>0.0000</td>\n      <td>Virgin America</td>\n      <td>NaN</td>\n      <td>jnardino</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>@VirginAmerica plus you've added commercials t...</td>\n      <td>NaN</td>\n      <td>2015-02-24 11:15:59 -0800</td>\n      <td>NaN</td>\n      <td>Pacific Time (US &amp; Canada)</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>570301083672813571</td>\n      <td>neutral</td>\n      <td>0.6837</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Virgin America</td>\n      <td>NaN</td>\n      <td>yvonnalynn</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n      <td>NaN</td>\n      <td>2015-02-24 11:15:48 -0800</td>\n      <td>Lets Play</td>\n      <td>Central Time (US &amp; Canada)</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>570301031407624196</td>\n      <td>negative</td>\n      <td>1.0000</td>\n      <td>Bad Flight</td>\n      <td>0.7033</td>\n      <td>Virgin America</td>\n      <td>NaN</td>\n      <td>jnardino</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>@VirginAmerica it's really aggressive to blast...</td>\n      <td>NaN</td>\n      <td>2015-02-24 11:15:36 -0800</td>\n      <td>NaN</td>\n      <td>Pacific Time (US &amp; Canada)</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>570300817074462722</td>\n      <td>negative</td>\n      <td>1.0000</td>\n      <td>Can't Tell</td>\n      <td>1.0000</td>\n      <td>Virgin America</td>\n      <td>NaN</td>\n      <td>jnardino</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>@VirginAmerica and it's a really big bad thing...</td>\n      <td>NaN</td>\n      <td>2015-02-24 11:14:45 -0800</td>\n      <td>NaN</td>\n      <td>Pacific Time (US &amp; Canada)</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>570300767074181121</td>\n      <td>negative</td>\n      <td>1.0000</td>\n      <td>Can't Tell</td>\n      <td>0.6842</td>\n      <td>Virgin America</td>\n      <td>NaN</td>\n      <td>jnardino</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>@VirginAmerica seriously would pay $30 a fligh...</td>\n      <td>NaN</td>\n      <td>2015-02-24 11:14:33 -0800</td>\n      <td>NaN</td>\n      <td>Pacific Time (US &amp; Canada)</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>570300616901320704</td>\n      <td>positive</td>\n      <td>0.6745</td>\n      <td>NaN</td>\n      <td>0.0000</td>\n      <td>Virgin America</td>\n      <td>NaN</td>\n      <td>cjmcginnis</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>@VirginAmerica yes, nearly every time I fly VX...</td>\n      <td>NaN</td>\n      <td>2015-02-24 11:13:57 -0800</td>\n      <td>San Francisco CA</td>\n      <td>Pacific Time (US &amp; Canada)</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>570300248553349120</td>\n      <td>neutral</td>\n      <td>0.6340</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Virgin America</td>\n      <td>NaN</td>\n      <td>pilot</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>@VirginAmerica Really missed a prime opportuni...</td>\n      <td>NaN</td>\n      <td>2015-02-24 11:12:29 -0800</td>\n      <td>Los Angeles</td>\n      <td>Pacific Time (US &amp; Canada)</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>570299953286942721</td>\n      <td>positive</td>\n      <td>0.6559</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Virgin America</td>\n      <td>NaN</td>\n      <td>dhepburn</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>@virginamerica Well, I didn't…but NOW I DO! :-D</td>\n      <td>NaN</td>\n      <td>2015-02-24 11:11:19 -0800</td>\n      <td>San Diego</td>\n      <td>Pacific Time (US &amp; Canada)</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>570295459631263746</td>\n      <td>positive</td>\n      <td>1.0000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Virgin America</td>\n      <td>NaN</td>\n      <td>YupitsTate</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>@VirginAmerica it was amazing, and arrived an ...</td>\n      <td>NaN</td>\n      <td>2015-02-24 10:53:27 -0800</td>\n      <td>Los Angeles</td>\n      <td>Eastern Time (US &amp; Canada)</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n## Before / After Cleaning\n\nBelow we show the first 10 tweets in their original form, then the cleaned `clean_text` column.\n\n::: {#1685f014 .cell execution_count=2}\n``` {.python .cell-code}\n# take a 10-row sample for demo\nsample = df_raw.head(10).copy()\n\n# apply the cleaning pipeline\ndf_tidy = preprocess(sample)\n\n# display side-by-side \npd.concat(\n    [\n        sample[[\"tweet_id\", \"text\"]].rename(columns={\"text\": \"original_text\"}),\n        df_tidy[[\"clean_text\"]]\n    ],\n    axis=1\n)\n```\n\n::: {.cell-output .cell-output-display execution_count=2}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>tweet_id</th>\n      <th>original_text</th>\n      <th>clean_text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>570306133677760513</td>\n      <td>@VirginAmerica What @dhepburn said.</td>\n      <td>what  said.</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>570301130888122368</td>\n      <td>@VirginAmerica plus you've added commercials t...</td>\n      <td>plus you've added commercials to the experienc...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>570301083672813571</td>\n      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n      <td>i didn't today... must mean i need to take ano...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>570301031407624196</td>\n      <td>@VirginAmerica it's really aggressive to blast...</td>\n      <td>it's really aggressive to blast obnoxious \"ent...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>570300817074462722</td>\n      <td>@VirginAmerica and it's a really big bad thing...</td>\n      <td>and it's a really big bad thing about it</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>570300767074181121</td>\n      <td>@VirginAmerica seriously would pay $30 a fligh...</td>\n      <td>seriously would pay $30 a flight for seats tha...</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>570300616901320704</td>\n      <td>@VirginAmerica yes, nearly every time I fly VX...</td>\n      <td>yes, nearly every time i fly vx this “ear worm...</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>570300248553349120</td>\n      <td>@VirginAmerica Really missed a prime opportuni...</td>\n      <td>really missed a prime opportunity for men with...</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>570299953286942721</td>\n      <td>@virginamerica Well, I didn't…but NOW I DO! :-D</td>\n      <td>well, i didn't...but now i do! :-d</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>570295459631263746</td>\n      <td>@VirginAmerica it was amazing, and arrived an ...</td>\n      <td>it was amazing, and arrived an hour early. you...</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n## Save to Parquet\n\nNow we save the full cleaned dataset to Parquet and display the path.\n\n::: {#908d5139 .cell execution_count=3}\n``` {.python .cell-code}\n# load & preprocess full dataset\nfull_raw  = load_raw()\nfull_tidy = preprocess(full_raw)\n\n# save and capture the file path\nout_path = save_parquet(full_tidy)\nprint(f\"✅ Saved {len(full_tidy):,} rows to:\\n{out_path}\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n✅ Saved 14,640 rows to:\nC:\\Projects\\twitter-airline-analysis\\data\\processed\\tweets.parquet\n```\n:::\n:::\n\n\n::: {#5f7a12d2 .cell execution_count=4}\n``` {.python .cell-code}\ndf = pd.read_parquet(PROC_DIR / \"tweets.parquet\") \nX    = df[\"clean_text\"]\ny    = df[\"airline_sentiment\"]\n\n# 20 % validation, 20 % test\nX_temp, X_test, y_temp, y_test = train_test_split(X, y,\n                                                  test_size=0.10,\n                                                  stratify=y,\n                                                  random_state=42)\nX_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp,\n                                                  test_size=0.1111,   # 0.1111 * 0.9 ≈ 0.10\n                                                  stratify=y_temp,\n                                                  random_state=42)\n\n# -----------------------------------------------\n# 3. SAVE as Feather (fast) for later notebooks\n# -----------------------------------------------\n(pd.Series(X_train,   name=\"text\")   .reset_index(drop=True)\n                                  .to_frame()\n                                  .to_feather(PROC_DIR / \"X_train.ftr\"))\n\n(pd.Series(y_train,   name=\"label\")  .reset_index(drop=True)\n                                   .to_frame()\n                                   .to_feather(PROC_DIR / \"y_train.ftr\"))\n\n(pd.Series(X_val,     name=\"text\")   .reset_index(drop=True)\n                                  .to_frame()\n                                  .to_feather(PROC_DIR / \"X_val.ftr\"))\n\n(pd.Series(y_val,     name=\"label\")  .reset_index(drop=True)\n                                   .to_frame()\n                                   .to_feather(PROC_DIR / \"y_val.ftr\"))\n\n(pd.Series(X_test,    name=\"text\")   .reset_index(drop=True)\n                                  .to_frame()\n                                  .to_feather(PROC_DIR / \"X_test.ftr\"))\n\n(pd.Series(y_test,    name=\"label\")  .reset_index(drop=True)\n                                   .to_frame()\n                                   .to_feather(PROC_DIR / \"y_test.ftr\"))\n\nprint(\"✅ Validation / test splits written to\", PROC_DIR.resolve())\n\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n✅ Validation / test splits written to C:\\Projects\\twitter-airline-analysis\\data\\processed\n```\n:::\n:::\n\n\n",
    "supporting": [
      "02_data_prep_files"
    ],
    "filters": [],
    "includes": {
      "include-in-header": [
        "<script src=\"https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js\" integrity=\"sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==\" crossorigin=\"anonymous\"></script>\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js\" integrity=\"sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==\" crossorigin=\"anonymous\" data-relocate-top=\"true\"></script>\n<script type=\"application/javascript\">define('jquery', [],function() {return window.jQuery;})</script>\n"
      ]
    }
  }
}