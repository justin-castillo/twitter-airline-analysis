{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "11ffd0cf",
   "metadata": {},
   "source": [
    "## 1 — global setup: seed, imports, deterministic backend   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd4c428",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\justi\\Anaconda3\\envs\\twitter-sentiment-env\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "RANDOM_SEED = 42\n",
    "\n",
    "# ── make project root importable ────────────────────────────────\n",
    "import sys\n",
    "import pathlib\n",
    "sys.path.append(str(pathlib.Path.cwd().parent))          # …/twitter-airline-analysis\n",
    "\n",
    "# ── stdlib ──────────────────────────────────────────────────────\n",
    "import os\n",
    "import random\n",
    "from pathlib import Path\n",
    "\n",
    "# ── third-party ────────────────────────────────────────────────\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt        # used for Optuna plots later\n",
    "import optuna\n",
    "from joblib                           import load, dump\n",
    "from sklearn import set_config\n",
    "from sklearn.pipeline                 import Pipeline\n",
    "from sklearn.feature_extraction.text  import TfidfVectorizer\n",
    "from sklearn.linear_model             import LogisticRegression\n",
    "from sklearn.metrics                  import roc_auc_score, classification_report, RocCurveDisplay\n",
    "from sklearn.model_selection          import train_test_split\n",
    "\n",
    "# ── local project code ─────────────────────────────────────────\n",
    "from twitter_airline_analysis.data_prep import load_prepared_data\n",
    "\n",
    "# ── global sklearn setting ─────────────────────────────────────\n",
    "set_config(transform_output=\"pandas\")\n",
    "\n",
    "# ── project paths ──────────────────────────────────────────────\n",
    "PROJECT_ROOT   = Path.cwd().resolve().parent\n",
    "BASELINE_PATH  = PROJECT_ROOT / \"models\" / \"logreg_tfidf.joblib\"\n",
    "TUNED_MODEL_PATH = PROJECT_ROOT / \"models\" / \"logreg_tfidf_optuna.joblib\"\n",
    "PROCESSED_DIR = PROJECT_ROOT / \"data\" / \"processed\"\n",
    "ARTIFACT_DIR  = PROJECT_ROOT / \"artifacts\"\n",
    "ARTIFACT_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "# ── reproducibility ────────────────────────────────────────────\n",
    "random.seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "os.environ[\"PYTHONHASHSEED\"] = str(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1207d40d",
   "metadata": {},
   "source": [
    "## 2 - load and split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27637e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _load(name: str):\n",
    "    \"\"\"Helper to read a Feather column and return a pandas Series / Index.\"\"\"\n",
    "    return pd.read_feather(PROCESSED_DIR / f\"{name}.ftr\")[name]\n",
    "\n",
    "# X, y splits already materialised during Module-4\n",
    "X_train = _load(\"X_train\")\n",
    "X_valid = _load(\"X_val\")\n",
    "X_test  = _load(\"X_test\")\n",
    "\n",
    "y_train = _load(\"y_train\")\n",
    "y_valid = _load(\"y_val\")\n",
    "y_test  = _load(\"y_test\")\n",
    "\n",
    "print(\n",
    "    \"Shapes —\",\n",
    "    f\"train: {X_train.shape},  valid: {X_valid.shape},  test: {X_test.shape}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad63ae7d",
   "metadata": {},
   "source": [
    "## 3 - Baseline Reference (Pre‑Optuna)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd4c695",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Falls back to training a minimal model\n",
    "if the file isn’t found, so the notebook remains runnable end-to-end.\n",
    "\"\"\"\n",
    "\n",
    "print(f\"Looking for baseline at: {BASELINE_PATH}\")\n",
    "\n",
    "if BASELINE_PATH.exists():\n",
    "    baseline_pipe = load(BASELINE_PATH)\n",
    "    print(\"✔ Loaded baseline artefact.\")\n",
    "else:\n",
    "    print(\"✗ Baseline artefact not found – training quick default model...\")\n",
    "    baseline_pipe = Pipeline([\n",
    "        (\"tfidf\", TfidfVectorizer(sublinear_tf=True)),\n",
    "        (\"clf\",   LogisticRegression(max_iter=500, n_jobs=-1, random_state=42)),\n",
    "    ])\n",
    "    baseline_pipe.fit(X_train, y_train)\n",
    "    BASELINE_PATH.parent.mkdir(exist_ok=True)\n",
    "    dump(baseline_pipe, BASELINE_PATH)\n",
    "    print(f\"Saved new baseline to {BASELINE_PATH}\")\n",
    "\n",
    "# ── validation metric ──────────────────────────────────────────\n",
    "baseline_preds = baseline_pipe.predict_proba(X_valid)[:, 1]\n",
    "baseline_auc   = roc_auc_score(y_valid, baseline_preds)\n",
    "\n",
    "print(f\"Baseline TF-IDF + LogReg AUC: {baseline_auc:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1961961d",
   "metadata": {},
   "source": [
    "## 3 - Optuna Setup\n",
    "\n",
    "The objective is deliberately lightweight; feature engineering is confined to TfidfVectorizer to keep search time reasonable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8276c0e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def objective(trial: optuna.Trial) -> float:\n",
    "    \"\"\"Return validation ROC-AUC for a single Optuna trial.\"\"\"\n",
    "    # ── pipeline definition ─────────────────────────────────────\n",
    "    pipeline = Pipeline([\n",
    "        (\n",
    "            \"tfidf\",\n",
    "            TfidfVectorizer(\n",
    "                max_df      = trial.suggest_float(\"max_df\", 0.7, 1.0),\n",
    "                min_df      = trial.suggest_int(\"min_df\", 1, 10),\n",
    "                ngram_range = (1, trial.suggest_int(\"max_ngram\", 1, 3)),\n",
    "                sublinear_tf=True,\n",
    "            ),\n",
    "        ),\n",
    "        (\n",
    "            \"clf\",\n",
    "            LogisticRegression(\n",
    "                C        = trial.suggest_loguniform(\"C\", 1e-3, 1e2),\n",
    "                penalty  = trial.suggest_categorical(\"penalty\", [\"l2\", \"elasticnet\"]),\n",
    "                solver   = \"saga\",\n",
    "                l1_ratio = (\n",
    "                    trial.suggest_float(\"l1_ratio\", 0.0, 1.0)\n",
    "                    if trial.params.get(\"penalty\") == \"elasticnet\"\n",
    "                    else None\n",
    "                ),\n",
    "                max_iter     = 500,\n",
    "                n_jobs       = -1,\n",
    "                random_state = RANDOM_SEED,\n",
    "            ),\n",
    "        ),\n",
    "    ])\n",
    "\n",
    "    # ── training & evaluation ───────────────────────────────────\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    preds  = pipeline.predict_proba(X_valid)[:, 1]\n",
    "    score  = roc_auc_score(y_valid, preds)\n",
    "\n",
    "    # Save pipeline so we can persist the best one later\n",
    "    trial.set_user_attr(\"pipeline\", pipeline)\n",
    "    return score\n",
    "\n",
    "# ── create / load study ────────────────────────────────────────\n",
    "study = optuna.create_study(\n",
    "    direction      = \"maximize\",\n",
    "    study_name     = \"logreg_tfidf_auc\",\n",
    "    pruner         = optuna.pruners.MedianPruner(n_warmup_steps=10),\n",
    "    storage        = f\"sqlite:///{ARTIFACT_DIR/'optuna_study.db'}\",\n",
    "    load_if_exists = True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "875fc074",
   "metadata": {},
   "source": [
    "## 4 - Run Study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc36211",
   "metadata": {},
   "outputs": [],
   "source": [
    "study.optimize(objective, n_trials=100, show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21e335ec",
   "metadata": {},
   "source": [
    "## 4 -  Persist & reload the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b2cddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_pipeline = study.best_trial.user_attrs[\"pipeline\"]   # retrieved from objective\n",
    "\n",
    "# Persist\n",
    "TUNED_MODEL_PATH.parent.mkdir(exist_ok=True)\n",
    "dump(best_pipeline, TUNED_MODEL_PATH)\n",
    "print(f\"✅ Saved tuned model → {TUNED_MODEL_PATH}\")\n",
    "\n",
    "# Reload to verify (optional sanity check)\n",
    "best_pipeline = load(TUNED_MODEL_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9f4f1cc",
   "metadata": {},
   "source": [
    "## 5 - Final evaluation on the held‑out test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a9a58d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = best_pipeline.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(classification_report(y_test, preds > 0.5, digits=3))\n",
    "RocCurveDisplay.from_predictions(y_test, preds)\n",
    "study.trials_dataframe().to_csv(ARTIFACT_DIR / \"optuna_trials.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b44ef46",
   "metadata": {},
   "source": [
    "## 6 - Persist artefacts"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "twitter-sentiment-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
