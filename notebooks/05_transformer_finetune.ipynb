{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "83d51277",
   "metadata": {},
   "source": [
    "# 05 – Transformer Fine‑Tune (DistilBERT)\n",
    "\n",
    "Fine‑tune a lightweight transformer (DistilBERT) on the **Twitter‑Airline Sentiment** dataset and benchmark it against the classical **TF‑IDF + Logistic Regression** baseline.\n",
    "\n",
    "> **Model** `distilbert‑base‑uncased`  \n",
    "> **Training split** 90 % of cleaned data (**stratified**)  \n",
    "> **Validation split** 10 % (held‑out during fine‑tuning)  \n",
    "> **Test set** Untouched split created in `04_baseline_model.ipynb`  \n",
    "> **Artifacts saved to** `models/distilbert_twitter/`\n",
    "\n",
    "---\n",
    "\n",
    "## Tools Used & Why  <!-- required by portfolio spec -->\n",
    "\n",
    "| Tool | Purpose | Why this tool |\n",
    "|------|---------|--------------|\n",
    "| **Hugging Face Transformers** | Pre‑trained DistilBERT weights & Trainer API | Industry standard for NLP transfer learning |\n",
    "| **Datasets** | Efficient dataset objects, streaming, mapping | Handles tokenisation, caching, and splits cleanly |\n",
    "| **PyTorch** | Back‑end tensor engine | Widely supported, mature, CUDA‑ready |\n",
    "| **evaluate** | Metrics (accuracy, F1) | Consistent with HF ecosystem |\n",
    "| **scikit‑learn** | Baseline metrics & confusion matrix | Lightweight, familiar API for classic ML |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84afaf23",
   "metadata": {},
   "source": [
    "## 0 Imports & Global Config  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b484394",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TRANSFORMERS_NO_TF\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac48629",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\justi\\Anaconda3\\envs\\twitter-sentiment-env\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# --- core -------------------------------------------------------------\n",
    "from pathlib import Path\n",
    "import random\n",
    "\n",
    "# --- third‑party ------------------------------------------------------\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# transformers / HF\n",
    "from transformers import (\n",
    "    AutoTokenizer, AutoModelForSequenceClassification,\n",
    "    TrainingArguments, Trainer, DataCollatorWithPadding\n",
    ")\n",
    "from datasets import Dataset \n",
    "from evaluate import load as load_metric\n",
    "import torch\n",
    "\n",
    "# --- reproducibility --------------------------------------------------\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "# --- paths ------------------------------------------------------------\n",
    "PROJ_ROOT  = Path.cwd()\n",
    "DATA_DIR   = PROJ_ROOT / \"data\" / \"processed\"\n",
    "MODEL_DIR  = PROJ_ROOT / \"models\" / \"distilbert_twitter\"\n",
    "MODEL_DIR.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "babfdf44",
   "metadata": {},
   "source": [
    "## 1 Load Cleaned Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6723e6a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>airline</th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>negativereason</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>570306133677760513</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>neutral</td>\n",
       "      <td>what  said.</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>570301130888122368</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>positive</td>\n",
       "      <td>plus you've added commercials to the experienc...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>570301083672813571</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>neutral</td>\n",
       "      <td>i didn't today... must mean i need to take ano...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>570301031407624196</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>negative</td>\n",
       "      <td>it's really aggressive to blast obnoxious \"ent...</td>\n",
       "      <td>Bad Flight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>570300817074462722</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>negative</td>\n",
       "      <td>and it's a really big bad thing about it</td>\n",
       "      <td>Can't Tell</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id         airline airline_sentiment  \\\n",
       "0  570306133677760513  Virgin America           neutral   \n",
       "1  570301130888122368  Virgin America          positive   \n",
       "2  570301083672813571  Virgin America           neutral   \n",
       "3  570301031407624196  Virgin America          negative   \n",
       "4  570300817074462722  Virgin America          negative   \n",
       "\n",
       "                                          clean_text negativereason  \n",
       "0                                        what  said.           None  \n",
       "1  plus you've added commercials to the experienc...           None  \n",
       "2  i didn't today... must mean i need to take ano...           None  \n",
       "3  it's really aggressive to blast obnoxious \"ent...     Bad Flight  \n",
       "4           and it's a really big bad thing about it     Can't Tell  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 14,640 tweets\n"
     ]
    }
   ],
   "source": [
    "PROJ_ROOT = Path.cwd().parent           # one level up from notebooks/\n",
    "DATA_DIR  = PROJ_ROOT / \"data\" / \"processed\"\n",
    "\n",
    "# Adjust filename to match actual parquet/CSV\n",
    "df = pd.read_parquet(DATA_DIR / \"tweets.parquet\")\n",
    "\n",
    "display(df.head())\n",
    "print(f\"Loaded {len(df):,} tweets\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5167e2ba",
   "metadata": {},
   "source": [
    "## 2 Train / Validation Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "541c82de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train rows: 13,176  │ Val rows: 1,464\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_df, val_df = train_test_split(\n",
    "    df,\n",
    "    test_size   = 0.10,\n",
    "    stratify    = df[\"airline_sentiment\"],\n",
    "    random_state= SEED,\n",
    ")\n",
    "\n",
    "print(f\"Train rows: {len(train_df):,}  │ Val rows: {len(val_df):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "190ae1a9",
   "metadata": {},
   "source": [
    "## 3 Tokenisation → HF Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a78c8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 13176/13176 [00:00<00:00, 20452.13 examples/s]\n",
      "Map: 100%|██████████| 1464/1464 [00:00<00:00, 26142.30 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['__index_level_0__', 'input_ids', 'attention_mask', 'labels'],\n",
      "    num_rows: 13176\n",
      "})\n",
      "Dataset({\n",
      "    features: ['__index_level_0__', 'input_ids', 'attention_mask', 'labels'],\n",
      "    num_rows: 1464\n",
      "})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "LABELS   = [\"negative\", \"neutral\", \"positive\"]\n",
    "label2id = {lab: i for i, lab in enumerate(LABELS)}\n",
    "id2label = {i: lab for lab, i in label2id.items()}\n",
    "\n",
    "tok = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "\n",
    "def encode(batch):\n",
    "    enc = tok(\n",
    "        batch[\"clean_text\"],\n",
    "        truncation=True,\n",
    "        max_length=128,\n",
    "    )\n",
    "    enc[\"labels\"] = [label2id[x] for x in batch[\"airline_sentiment\"]]\n",
    "    return enc\n",
    "\n",
    "cols = [\"clean_text\", \"airline_sentiment\"]\n",
    "\n",
    "train_ds = Dataset.from_pandas(train_df[cols]).map(encode, batched=True,\n",
    "                                                   remove_columns=cols)\n",
    "val_ds   = Dataset.from_pandas(val_df[cols]).map(encode, batched=True,\n",
    "                                                 remove_columns=cols)\n",
    "\n",
    "print(train_ds)\n",
    "print(val_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2e2b109",
   "metadata": {},
   "source": [
    "## 4 Model Instantiation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b51087a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"distilbert-base-uncased\",\n",
    "    num_labels = len(LABELS),\n",
    "    id2label   = id2label,\n",
    "    label2id   = label2id,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3250125",
   "metadata": {},
   "source": [
    "## 5 Training Arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "68342dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS      = 2\n",
    "BATCH_SIZE  = 16\n",
    "LEARNING_RATE = 2e-5\n",
    "\n",
    "train_args = TrainingArguments(\n",
    "    output_dir              = MODEL_DIR,\n",
    "    eval_strategy     = \"epoch\",\n",
    "    save_strategy           = \"epoch\",\n",
    "    learning_rate           = LEARNING_RATE,\n",
    "    per_device_train_batch_size = BATCH_SIZE,\n",
    "    per_device_eval_batch_size  = BATCH_SIZE,\n",
    "    num_train_epochs        = EPOCHS,\n",
    "    weight_decay            = 0.01,\n",
    "    logging_steps           = 50,\n",
    "    seed                    = SEED,\n",
    "    report_to               = \"none\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a859e879",
   "metadata": {},
   "source": [
    "## 6 Trainer + Fine‑Tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "531b6697",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\justi\\Anaconda3\\envs\\twitter-sentiment-env\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1648' max='1648' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1648/1648 30:10, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.416100</td>\n",
       "      <td>0.444006</td>\n",
       "      <td>0.835383</td>\n",
       "      <td>0.782617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.333600</td>\n",
       "      <td>0.450154</td>\n",
       "      <td>0.838798</td>\n",
       "      <td>0.791774</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\justi\\Anaconda3\\envs\\twitter-sentiment-env\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1648, training_loss=0.41087919589385247, metrics={'train_runtime': 1812.3851, 'train_samples_per_second': 14.54, 'train_steps_per_second': 0.909, 'total_flos': 256589787423456.0, 'train_loss': 0.41087919589385247, 'epoch': 2.0})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_collator = DataCollatorWithPadding(tokenizer=tok, return_tensors=\"pt\")\n",
    "\n",
    "metric_acc = load_metric(\"accuracy\")\n",
    "metric_f1  = load_metric(\"f1\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    preds = eval_pred.predictions.argmax(-1)\n",
    "    refs  = eval_pred.label_ids\n",
    "    return {\n",
    "        \"accuracy\": metric_acc.compute(predictions=preds, references=refs)[\"accuracy\"],\n",
    "        \"f1\": metric_f1.compute(predictions=preds, references=refs, average=\"macro\")[\"f1\"],\n",
    "    }\n",
    "\n",
    "trainer = Trainer(\n",
    "    model           = model,\n",
    "    args            = train_args,\n",
    "    train_dataset   = train_ds,\n",
    "    eval_dataset    = val_ds,\n",
    "    data_collator   = data_collator,\n",
    "    compute_metrics = compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09d1483b",
   "metadata": {},
   "source": [
    "## 7 Evaluation on Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2fa086e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\justi\\Anaconda3\\envs\\twitter-sentiment-env\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='92' max='92' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [92/92 00:19]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.4501541554927826,\n",
       " 'eval_accuracy': 0.8387978142076503,\n",
       " 'eval_f1': 0.7917735076611953,\n",
       " 'eval_runtime': 19.4595,\n",
       " 'eval_samples_per_second': 75.233,\n",
       " 'eval_steps_per_second': 4.728,\n",
       " 'epoch': 2.0}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_metrics = trainer.evaluate()\n",
    "val_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46a40ba7",
   "metadata": {},
   "source": [
    "## 8 Save Artifacts & Export"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "twitter-sentiment-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
